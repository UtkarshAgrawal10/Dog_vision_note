{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dog-vision.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xSmj0jf89tf6",
        "ZlB6naNcuEYX",
        "7-3MimTmTW4F",
        "vEUh18O_hcNK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "o0wQXCfORGWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-end Multi-class Dog Breed Classification\n",
        "\n",
        "This notebook builds an end-to-end multi-class image classifier using Tensorflow 2 and TensorFlow Hub.\n",
        "\n",
        "## 1. Problem\n",
        "\n",
        "Identifying the breed of a dog given an image of a dog.\n",
        "\n",
        "## 2. Data \n",
        "\n",
        "The data we're using is from https://www.kaggle.com/c/dog-breed-identification/data\n",
        "\n",
        "## 3. Evaluation\n",
        "\n",
        "The evaluation is a file with prediction probabilities for each dog breed of each test image.\n",
        "\n",
        "https://www.kaggle.com/c/dog-breed-identification/overview/evaluation\n",
        "\n",
        "## 4. Features\n",
        "\n",
        "Some information about the data:\n",
        "* We're dealing with images (unstructured data) so it's probably best we use deep learning/transfer learning\n",
        "* There are 120 breeds of dogs (this means there are 120 different classes). \n",
        "* There are around 10000+ images in the training(have labels) and test set(have no labels) each\n"
      ],
      "metadata": {
        "id": "qlLGbVqZRKy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the uploaded file in drive\n",
        "# !unzip \"/content/drive/MyDrive/Dog Vision/dog-breed-identification.zip\" -d \"drive/MyDrive/Dog Vision/\""
      ],
      "metadata": {
        "id": "VNG0xvx49iv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get our workspace ready\n",
        "\n",
        "* Import TensorFlow 2.x ✅\n",
        "* Import TensorFlow Hub ✅\n",
        ""
      ],
      "metadata": {
        "id": "-y4qY0vERAeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary tools\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub \n",
        "print(\"TF version\",tf.__version__)\n",
        "print(\"TF Hub version:\", hub.__version__)\n",
        "\n",
        "# Check for GPU availability\n",
        "print(\"GPU\",\"available\" if tf.config.list_physical_devices(\"GPU\") else \"not available\")"
      ],
      "metadata": {
        "id": "68dUBRrNEwuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Getting our data ready (turning into Tensors)\n",
        "\n",
        " With all machine learning models, our data has to be in numerical format.Turning our images into Tensors (numerical representations).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "E8v0o1pbE1LS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "labels_csv = pd.read_csv(\"drive/MyDrive/Dog Vision/labels.csv\")\n",
        "print(labels_csv.describe())\n",
        "print(labels_csv.head())"
      ],
      "metadata": {
        "id": "wYB25NIcrGKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How amny images are there of each breed?\n",
        "labels_csv[\"breed\"].value_counts().plot.bar(figsize=(20,10))"
      ],
      "metadata": {
        "id": "jmAKNf06ruA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv[\"breed\"].value_counts().median()"
      ],
      "metadata": {
        "id": "lsHmEPSEswWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's view an image\n",
        "from IPython.display import Image\n",
        "Image(\"drive/MyDrive/Dog Vision/train/001513dfcb2ffafc82cccf4d8bbaba97.jpg\")"
      ],
      "metadata": {
        "id": "MQc_pPiHtRH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting images and their labels\n",
        "\n",
        "Getting a list of all our image file pathnames."
      ],
      "metadata": {
        "id": "fITbP81Zu_IA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " labels_csv.head()"
      ],
      "metadata": {
        "id": "fxznHj8Zvlh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create pathnames from Image ID's\n",
        "filenames = [\"drive/MyDrive/Dog Vision/train/\"+ fname + \".jpg\" for fname in labels_csv[\"id\"]]\n",
        "filenames[:10]"
      ],
      "metadata": {
        "id": "RlHWrSlQvenz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Check whether number of filenames matches number of actual image files\n",
        "import os\n",
        "if len(os.listdir(\"drive/MyDrive/Dog Vision/train/\"))==len(filenames):\n",
        "  print(\"Filenames match actual amount of files\")\n",
        "else:\n",
        "  print(\"Filenames do not match actual amount of files\")"
      ],
      "metadata": {
        "id": "WFoSDDmGv-Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing our labels\n"
      ],
      "metadata": {
        "id": "LFEn_RhLzPCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "labels = labels_csv[\"breed\"].to_numpy()\n",
        "#labels = np.array(labels) # does same thing as above\n",
        "labels"
      ],
      "metadata": {
        "id": "7gjTyNyqxc96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "metadata": {
        "id": "eTm7KfMRxObV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See if number of labels matches the number of filenames\n",
        "if len(labels) == len(filenames):\n",
        "  print(\"Number of labels matches number of filenames\")\n",
        "else:\n",
        "  print(\"Number of labels do not match number of filenames\")"
      ],
      "metadata": {
        "id": "Olk8WFlgzv5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the unique label values\n",
        "unique_breeds = np.unique(labels)\n",
        "len(unique_breeds)"
      ],
      "metadata": {
        "id": "-nIbdczp0b6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a single label into an array of booleans\n",
        "print(labels[0])\n",
        "labels[0]==unique_breeds"
      ],
      "metadata": {
        "id": "2RYdi6fH0x_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn every label into a boolean array\n",
        "boolean_labels = [label == unique_breeds for label in labels]\n",
        "boolean_labels[:2]"
      ],
      "metadata": {
        "id": "Yk6LUyRY1Jq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(boolean_labels)"
      ],
      "metadata": {
        "id": "nPv9h1DU25Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Turning boolean array into intergers\n",
        "print(labels[0]) # orignal label\n",
        "print(np.where(unique_breeds == labels[0])) # index where label occurs\n",
        "print(boolean_labels[0].argmax()) # index where label occurs in boolean array\n",
        "print(boolean_labels[0].astype(int)) # there will be a 1 where the sample label occurs"
      ],
      "metadata": {
        "id": "5AFYyXhO28nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating our own validation set\n",
        "Since the dataset form Kaggle doesn't come with a validation set, we're going to create our own"
      ],
      "metadata": {
        "id": "xSmj0jf89tf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup X & y variables\n",
        "X = filenames\n",
        "y = boolean_labels"
      ],
      "metadata": {
        "id": "ny04eP2-7i6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to start off experimenting with ~1000 images and increase as needed"
      ],
      "metadata": {
        "id": "7AJc2YWp-lkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Set number of images to use for experimenting\n",
        " NUM_IMAGES =  1000#@param (type:\"slider\",min:1000,max=10000,step:100)"
      ],
      "metadata": {
        "id": "KzhTFA9R-Stv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's split our data into train and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split them into training and validation of total size NUM_IMAGES\n",
        "X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],\n",
        "                                                  y[:NUM_IMAGES],\n",
        "                                                  test_size = 0.2,\n",
        "                                                  random_state = 42) \n",
        "\n",
        "len(X_train), len(y_train), len(X_val), len(y_val)"
      ],
      "metadata": {
        "id": "V_FhF-Ou_wNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gees at the training data\n",
        "X_train[:5], y_train[:2]"
      ],
      "metadata": {
        "id": "IMlam8IrA_7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Images (turning images into Tensors)\n",
        "\n",
        "The following function\n",
        "1. Takes an image filepath as input\n",
        "2. Use TensorFlow to read the file and save it to a variable, `image`\n",
        "3. Turn our `image` (a jpg) into Tensors\n",
        "4. Resize the `image` to be a shape of (224,224)\n",
        "5. Return the modified `image`"
      ],
      "metadata": {
        "id": "8kSJLBXxCLFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert an image to NumPy array\n",
        "from matplotlib.pyplot import imread\n",
        "image = imread(filenames[42])\n",
        "image.shape"
      ],
      "metadata": {
        "id": "eTUXkfKkAu9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.max(), image.min()"
      ],
      "metadata": {
        "id": "wjcKHorgFPO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn image into tensor\n",
        "tf.constant(image)"
      ],
      "metadata": {
        "id": "G_K5JUThFpdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've seen what an image looks like as a Tensor, let's make a function to preprocess them."
      ],
      "metadata": {
        "id": "e5KWgkRFGVbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image size\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# Create a function for preprocessing images\n",
        "def process_image(image_path):\n",
        "  \"\"\"\n",
        "  Takes an image file path and turns the image into a Tensor.\n",
        "  \"\"\"\n",
        "\n",
        "  # Read in an image file\n",
        "  image = tf.io.read_file(image_path)\n",
        "  # Turn the jpeg image into numerical Tensors with 3 colur channels(RGB)\n",
        "  image = tf.image.decode_jpeg(image,channels=3)\n",
        "  # Convert the colur channel values from 0-225 to 0-1 va;ues\n",
        "  image = tf.image.convert_image_dtype(image,tf.float32)\n",
        "  # Resize the image to our desired value(224,224)\n",
        "  image = tf.image.resize(image, size =[IMG_SIZE,IMG_SIZE])\n",
        "  return image"
      ],
      "metadata": {
        "id": "r6Tn2njfFsup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turning our data into batches\n",
        "\n",
        "We turn our data into batches because if we're trying to precess 10000+ images in one go.. they might not fit into memory.\n",
        "\n",
        "So that's why we do about 32 (this is the batch size) images at a time (you can manually adjust the batch size if need be)\n",
        "\n",
        "In order to use Tensorflow effectively, we need our data in the form of Tensor tuples which look like this:\n",
        "`(image,label)`"
      ],
      "metadata": {
        "id": "deckIH_rRXa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a simple function to a return a tuple (image,label)\n",
        "def get_image_label(image_path,label):\n",
        "  \"\"\"\n",
        "  Takes an image dile path name and the assosicated label,\n",
        "  processes the image and return a tuple of (image,label).\n",
        "  \"\"\"\n",
        "  image = process_image(image_path)\n",
        "  return image,label\n"
      ],
      "metadata": {
        "id": "BcbPOAyJL3s7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo of the above\n",
        "(process_image(X[42]),tf.constant(y[42]))"
      ],
      "metadata": {
        "id": "7JyeZIthTE8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got a way to turn our data into tuples of Tensors in the form: `(image,label)`, let's make a function to turn all of our data (`X` and `y`) into batches!"
      ],
      "metadata": {
        "id": "GasPfH6GiP9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the batch size, 32 is a good start\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create a function to turn data into batches\n",
        "def create_data_batches(X, y=None , batch_size=BATCH_SIZE, valid_data=False,test_data=False):\n",
        "  \"\"\"\n",
        "  Creates batches of data out of image (X) and label (y) pairs.\n",
        "  Shuffles the data if it's training data but doesn't shuffle if it's validation data.\n",
        "  Also accepts test data as input(no labels).\n",
        "  \"\"\"\n",
        "\n",
        "  # if the data is a test dataset, we probably don't have labels\n",
        "  if test_data:\n",
        "    print(\"Creating test data batches...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) # only filepaths (no labels)\n",
        "    data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "\n",
        "  # if the data is a valid dataset, we don't need to shuffle it\n",
        "  elif valid_data:\n",
        "    print(\"Creating validation data batches...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # filepaths \n",
        "                                               tf.constant(y))) #labels\n",
        "    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  else:\n",
        "    print(\"Creating training data batches...\")\n",
        "    # Turn file paths and labels into Tensors\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X),\n",
        "                                               tf.constant(y)))\n",
        "    #Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n",
        "    data = data.shuffle(buffer_size=len(X)) \n",
        "    # Create (image,label) tuples(this also turns the image path into a processed image)\n",
        "    data = data.map(get_image_label)\n",
        "    #Turn the training data into batches\n",
        "    data_batch =data.batch(BATCH_SIZE)\n",
        "  return data_batch"
      ],
      "metadata": {
        "id": "-rvNiVu1Trel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and validation data batches\n",
        "train_data = create_data_batches(X_train, y_train)\n",
        "val_data = create_data_batches(X_val, y_val,valid_data=True)"
      ],
      "metadata": {
        "id": "ohwL0cHasZc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the different attributes of our data batches\n",
        "train_data.element_spec, val_data.element_spec"
      ],
      "metadata": {
        "id": "twyZHs5Ctozg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing Data Batches\n",
        "\n",
        "Our data is now in batches, however, these can be a little hard to understand/comprehend, let's visulaize them!\n"
      ],
      "metadata": {
        "id": "ZlB6naNcuEYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a function for viewing images in a data batch\n",
        "def show_25_images(images, labels):\n",
        "  \n",
        "  \"\"\"\n",
        "  Displays a plot of 25 images and their labels from a data batch,\n",
        "  \"\"\"\n",
        "\n",
        "  #Setup the figure\n",
        "  plt.figure(figsize=(10,10))\n",
        "  # Loop through 25 (for displaying 25 images)\n",
        "  for i in range(25):\n",
        "    # Create subplots(5 rows,5 columns)\n",
        "    ax=plt.subplot(5,5,i+1)\n",
        "    #. Display an image\n",
        "    plt.imshow(images[i])\n",
        "    # Add the image label as the title\n",
        "    plt.title(unique_breeds[labels[i].argmax()])\n",
        "    # Turn the grid lines off\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "jOqRRZ8AzILj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's visualize the data in a traing batch\n",
        "train_images, train_labels = next(train_data.as_numpy_iterator())\n",
        "show_25_images(train_images,train_labels)"
      ],
      "metadata": {
        "id": "zTkqKVnX0tO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's visualize our validation set\n",
        "val_images, val_labels =next(val_data.as_numpy_iterator())\n",
        "show_25_images(val_images, val_labels)"
      ],
      "metadata": {
        "id": "97j_p49G1KVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a model\n",
        "There are a few things we need to define:\n",
        "* The input shape (our images shape, in the form of Tensors) to our model.\n",
        "* The output shape (image labels, in the form of Tensors) of our model.\n",
        "* The URL of the model we want to use.https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\n"
      ],
      "metadata": {
        "id": "dgdRhvSu18xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup input shape to the model\n",
        "INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] #batch, height, width, colur channels\n",
        "\n",
        "# Setup output shape of our model\n",
        "OUTPUT_SHAPE = len(unique_breeds)\n",
        "\n",
        "# Setup model URL from TensorFlow Hub\n",
        "MODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\""
      ],
      "metadata": {
        "id": "DErIomgd9fjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got our inputs, outputs and model ready to go. Let's put them together into a Keras deep learning model!\n",
        "\n",
        "Knowing ths, let's create a function which:\n",
        "* Takes the input shape, output shape and the model we've chosen as paramters.\n",
        "* Defines the layers in Keras model in sequential fashion (do this first, then this, then that).\n",
        "* Compiles the model (says it should be evalutaed and improved).\n",
        "* Builds the model (tells the model the input shape it'll be getting).\n",
        "* Returns the model.\n",
        "\n",
        "All of these steps can be found here:\n",
        "https://www.tensorflow.org/guide/keras/sequential_model"
      ],
      "metadata": {
        "id": "Xo_cdImUPlWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function which builds a Keras model\n",
        "def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):\n",
        "  print(\"Building model with:\", MODEL_URL)\n",
        "\n",
        "  # Setup the model layers\n",
        "  model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n",
        "    tf.keras.layers.Dense(units = OUTPUT_SHAPE,\n",
        "                          activation = \"softmax\") # Layer 2 (output layer)\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "      optimizer=tf.keras.optimizers.Adam(),\n",
        "      metrics=[\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  # Build the model\n",
        "  model.build(INPUT_SHAPE)\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "Q02L5dHiSZTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "mPBYwbufIlD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = np.ones(shape=(1,1,1280))\n",
        "outputs"
      ],
      "metadata": {
        "id": "6t4BLPKAWSEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating callbacks \n",
        "\n",
        "Callbacks are helper functions a model can use during training to do such things such as save its progress, check its progress or stop training early if the model stops improving.\n",
        "\n",
        "We'll create two callbacks, one for TensorBoard which helps track our models progress and another for early stopping which prevents our model from training for too long.\n",
        "\n",
        "### TensorBoard Callback\n",
        "\n",
        "To setup a tensorboard callback, we need to do 3 things:\n",
        "1. Load the TensorBoard notebook extension\n",
        "2. Create a TensorBoard callback which is able to save logs to a directory and pass it to our model's `fit()` function.\n",
        "3. Visualize our models training logs with the `%tensorboard` magic function (we'll do this after model training)."
      ],
      "metadata": {
        "id": "HcCwFsS4Pc1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "O1fGvVqVG-_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "# Create a function to build a TensorBoard callback\n",
        "def create_tensorboard_callback():\n",
        "  # Create a log directory for storing TensorBoard logs\n",
        "  logdir = os.path.join(\"drive/MyDrive/Dog Vision/logs\",\n",
        "                        # Make it so the logs get tracked whenever we run an experiment\n",
        "                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  return tf.keras.callbacks.TensorBoard(logdir)"
      ],
      "metadata": {
        "id": "xeQJ6VvVRL2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Early Stopping Callback\n",
        "\n",
        "Early stopping helps stop our model from overfitting by stopping training if a certain evaluation metrics stops improving\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n"
      ],
      "metadata": {
        "id": "7-3MimTmTW4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create early stopping casllback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                  patience=3)"
      ],
      "metadata": {
        "id": "Jc9Wt8s5VDw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a model (on subset of data)\n",
        "\n",
        "Our first model is only going to train on 1000 images, to make sure everything is working."
      ],
      "metadata": {
        "id": "S9IPTUjbWawo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 100 #@param {type:\"slider\", min:10, max:100, step:10}"
      ],
      "metadata": {
        "id": "Ad4B1Fa6V6_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to make sure we're still running on a GPU\n",
        "print(\"GPU\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"not available\")"
      ],
      "metadata": {
        "id": "FfEszAGqXgaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a function which trains a model.\n",
        "\n",
        "* Create a model using `create_model()`\n",
        "* Setup a TensorBoard callback using `create_tensorboard_callback()`\n",
        "* Call the `fit()` function on our model passing it the training data, validation data, number of epochs to train for (`NUM_EPOCHS`) and the callbacks we'd like to use\n",
        "* Return the model"
      ],
      "metadata": {
        "id": "KXbvY_1iYfYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a function to train and return the trained model\n",
        "def train_model():\n",
        "  \"\"\"\n",
        "  Trains a given model and returns the trained version.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a model\n",
        "  model = create_model()\n",
        "\n",
        "  # Create new TensorBoard seesion everytime we train a model\n",
        "  tensorboard = create_tensorboard_callback()\n",
        "\n",
        "  # Fit the model to the data passing the callbacks we created\n",
        "  model.fit(x=train_data,\n",
        "            epochs = NUM_EPOCHS,\n",
        "            validation_data=val_data,\n",
        "            validation_freq=1,\n",
        "            callbacks=[tensorboard,early_stopping])\n",
        "  # Return the fitted model\n",
        "  return model"
      ],
      "metadata": {
        "id": "Dirk62gHYZyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the data\n",
        "model = train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi8522tGZMvq",
        "outputId": "2197e0d2-aead-4a6a-dce3-0b07cd542175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model with: https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\n",
            "Epoch 1/100\n",
            "25/25 [==============================] - 102s 3s/step - loss: 4.6328 - accuracy: 0.1075 - val_loss: 3.4759 - val_accuracy: 0.2600\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 74s 3s/step - loss: 1.6715 - accuracy: 0.6687 - val_loss: 2.2298 - val_accuracy: 0.4850\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 69s 3s/step - loss: 0.5750 - accuracy: 0.9450 - val_loss: 1.7219 - val_accuracy: 0.6050\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 43s 2s/step - loss: 0.2571 - accuracy: 0.9875 - val_loss: 1.5445 - val_accuracy: 0.6450\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 72s 3s/step - loss: 0.1467 - accuracy: 0.9950 - val_loss: 1.4494 - val_accuracy: 0.6550\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 44s 2s/step - loss: 0.0998 - accuracy: 1.0000 - val_loss: 1.4199 - val_accuracy: 0.6500\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 46s 2s/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 1.3914 - val_accuracy: 0.6700\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 1.3625 - val_accuracy: 0.6700\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 70s 3s/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 1.3466 - val_accuracy: 0.6750\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 73s 3s/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 1.3330 - val_accuracy: 0.6850\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 68s 3s/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 1.3210 - val_accuracy: 0.6850\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 58s 2s/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 1.3081 - val_accuracy: 0.6850\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 43s 2s/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 1.3034 - val_accuracy: 0.6950\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 44s 2s/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.2940 - val_accuracy: 0.6900\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 43s 2s/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 1.2872 - val_accuracy: 0.6950\n",
            "Epoch 16/100\n",
            "16/25 [==================>...........] - ETA: 11s - loss: 0.0197 - accuracy: 1.0000"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Question:** It looks like our model is overfitting because it's performing far better on the training dataset than the validation dataset, what are some ways to prevent model overfitting in deep learning neural networks?\n",
        "\n",
        "\n",
        "**Note:** Overfitting to begin with is a good thing! It means our model is learning!!"
      ],
      "metadata": {
        "id": "1itmLqjWa-xD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the TensorBoard logs\n",
        "\n",
        "The TensorBoard magic function (`%tensorboard`) will access the logs directory we created earlier and visualize its contents."
      ],
      "metadata": {
        "id": "vEUh18O_hcNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%tensorboard --logdir /content/drive/MyDrive/Dog\\ Vision/logs"
      ],
      "metadata": {
        "id": "VSpdOJHCg3Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making and evaluating predictions using a trained model"
      ],
      "metadata": {
        "id": "715G1qmDiI35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_data"
      ],
      "metadata": {
        "id": "8Q8Dq75juNq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation data (not used to train on)\n",
        "predictions = model.predict(val_data, verbose=1)\n",
        "predictions"
      ],
      "metadata": {
        "id": "Sv-VqMi-rRvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First prediction\n",
        "index = 42\n",
        "print(predictions[index])\n",
        "print(f\"Max value(probability of prediction): {np.max(predictions[index])}\")\n",
        "print(f\"Sum: {np.sum(predictions[index])}\")\n",
        "print(f\"Max index: {np.argmax(predictions[index])}\")\n",
        "print(f\"Predicted label: {unique_breeds[np.argmax(predictions[index])]}\")"
      ],
      "metadata": {
        "id": "aaex-v8_wEyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Havingh the above functionality is great but we want to be able to do it at scale.\n",
        "\n",
        "And it would be even better if we could see the image when the prediction is being made on!\n",
        "\n",
        "**Note:** Prediction probabilities are also known as confidence levels."
      ],
      "metadata": {
        "id": "skDETtPh1ild"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilties into their respective label(easier to understand)\n",
        "def get_pred_label(prediction_probabilities):\n",
        "  \"\"\"\n",
        "  Turns an array of prediction probabilities into a label.\n",
        "  \"\"\"\n",
        "\n",
        "  return unique_breeds[np.argmax(prediction_probabilities)]\n",
        "\n",
        "# Get a predicted label based on array of prediction probabilities \n",
        "pred_label = get_pred_label(predictions[0])\n",
        "pred_label"
      ],
      "metadata": {
        "id": "nCa80AicvN3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now since our vaidation data is still in a batch dataset, we'll have to unbatchify it to make predictions on the validation images and then compare those predictions to the validation labels(truth labels)."
      ],
      "metadata": {
        "id": "-CrSMSwl4_2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_data"
      ],
      "metadata": {
        "id": "480TjCk52_kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to unbatch a batch dataset\n",
        "def unbatchify(data):\n",
        "  \"\"\"\n",
        "  Takes a batched dataset of (image,label) Tensors and returns separate arrays of images and labels.\n",
        "  \"\"\"\n",
        "\n",
        "  images=[]\n",
        "  labels=[]\n",
        "  # Loop through unbatched data\n",
        "  for image, label in data.unbatch().as_numpy_iterator():\n",
        "    images.append(image)\n",
        "    labels.append(unique_breeds[np.argmax(label)])\n",
        "  return images, labels\n",
        "\n",
        "\n",
        "# Unbatchify the validation data \n",
        "val_images, val_labels = unbatchify(val_data)\n",
        "val_images[0], val_labels[0]"
      ],
      "metadata": {
        "id": "TVH7fc8v5-JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got ways to get:\n",
        "* Prediction labels\n",
        "* Validation labels (truth labels)\n",
        "* Validation images\n",
        "\n",
        "Let's make some function to make these all a bit more visualize\n",
        "\n",
        "We'll create a function which:\n",
        "* Takes an array of prediction probabilities, an array of truth labels and an array of images and an integer.\n",
        "* Convert the prediction probabilities to a predicted label.\n",
        "* Plot the predicted label, its predicted probability, the truth label and the target image on a single plot"
      ],
      "metadata": {
        "id": "vGhF22JY9rxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pred(prediction_probabilities, labels, images, n=1):\n",
        "  \"\"\"\n",
        "  View the prediction, ground truth and image for sample n\n",
        "  \"\"\"\n",
        "  pred_prob, true_label,image = prediction_probabilities[n], labels[n] ,images[n]\n",
        "\n",
        "  # Get the pred label\n",
        "  pred_label = get_pred_label(pred_prob)\n",
        "\n",
        "  # Plot image & remove ticks\n",
        "  plt.imshow(image)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  # Change the color of the title depending on if the prediction is right or wrong\n",
        "  if pred_label==true_label:\n",
        "    color=\"green\"\n",
        "  else:\n",
        "    color=\"red\"\n",
        "\n",
        "  # Change plot title to be predicted, probability of prediction and truth label\n",
        "  plt.title(\"{} {:2.0f}% {}\".format(pred_label,\n",
        "                                    np.max(pred_prob)*100,\n",
        "                                    true_label),\n",
        "                                    color=color)\n",
        "\n"
      ],
      "metadata": {
        "id": "AByBAZJd7I0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pred(prediction_probabilities=predictions,\n",
        "          labels=val_labels,\n",
        "          images=val_images,\n",
        "          n=77)"
      ],
      "metadata": {
        "id": "I8l4TK0f-ycH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got one function to visualize our models predictions, let's make another to view our models top 10 predictions.\n",
        "\n",
        "This function will:\n",
        "* Take an input of prediction probabilities array and a ground truth array and an integer\n",
        "* Find the prediction using `get_pred_label()`\n",
        "* Find the top 10:\n",
        "  * Prediction probabilities indexes\n",
        "  * Prediction probabilities values\n",
        "  * Prediction labels\n",
        "* Plot the top 10 prediction probability values and labels, coloring the true label green"
      ],
      "metadata": {
        "id": "Colmaab9EVmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pred_conf(prediction_probabilities, labels, n=1):\n",
        "  \"\"\"\n",
        "  Plot the top 10 highest prediction confidences along with the truth label for sample n.\n",
        "  \"\"\"\n",
        "  \n",
        "  pred_prob, true_label = prediction_probabilities[n], labels[n]\n",
        "\n",
        "  # Get the predicted label\n",
        "  pred_label = get_pred_label(pred_prob)\n",
        "  # Find the top 10 prediction confidence indexes\n",
        "  top_10_pred_indexes = pred_prob.argsort()[-10:][::-1]\n",
        "\n",
        "  # Find the top 10 prediction confidence values\n",
        "  top_10_pred_values = pred_prob[top_10_pred_indexes]\n",
        "\n",
        "  # Find the top 10 prediction labels\n",
        "  top_10_pred_labels = unique_breeds[top_10_pred_indexes]\n",
        "  # Setup plot\n",
        "  top_plot = plt.bar(np.arange(len(top_10_pred_labels)),\n",
        "                     top_10_pred_values,\n",
        "                     color=\"grey\")\n",
        "  plt.xticks(np.arange(len(top_10_pred_labels)),\n",
        "             labels=top_10_pred_labels,\n",
        "             rotation=\"vertical\")\n",
        "  # Change color of true label\n",
        "  if np.isin(true_label,top_10_pred_labels):\n",
        "    top_plot[np.argmax(top_10_pred_labels == true_label)].set_color(\"green\")\n",
        "  else:\n",
        "    pass"
      ],
      "metadata": {
        "id": "mcPTmSuGA0wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pred_conf(prediction_probabilities=predictions,\n",
        "               labels=val_labels,\n",
        "               n=9)"
      ],
      "metadata": {
        "id": "2pC7c7QuJDAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got some functions to help us visualize our predictions and evaluate our model, let's check out a few."
      ],
      "metadata": {
        "id": "IEGuRBGZNksI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check out a few predictions and their different values\n",
        "i_multiplier = 10\n",
        "num_rows = 5\n",
        "num_cols = 2\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize = (10*num_cols, 5*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows,2*num_cols,2*i+1)\n",
        "  plot_pred(prediction_probabilities=predictions,\n",
        "            labels=val_labels,\n",
        "            images=val_images,\n",
        "            n=i+i_multiplier)\n",
        "  plt.subplot(num_rows,2*num_cols,2*i+2)\n",
        "  plot_pred_conf(prediction_probabilities=predictions,\n",
        "                 labels=val_labels,\n",
        "                 n=i+i_multiplier)\n",
        "plt.tight_layout(h_pad=1.0) \n",
        "plt.show()\n",
        "  "
      ],
      "metadata": {
        "id": "vSUU83qRJLYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and loading a trained model"
      ],
      "metadata": {
        "id": "mNPyP6hgRW2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to save a model\n",
        "def save_model(model,suffix=None):\n",
        "  \"\"\"\n",
        "  Saves a given model in a models directory and appends a suffix(string).\n",
        "  \"\"\"\n",
        "  #Create a model directry pathname with current time\n",
        "  modeldir = os.path.join(\"drive/MyDrive/Dog Vision/models\",\n",
        "                          datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n",
        "  model_path = modeldir + \"-\" + suffix + \".h5\" #save format of model\n",
        "  print(f\"Saving model to: {model_path}...\")\n",
        "  model.save(model_path)\n",
        "  return model_path"
      ],
      "metadata": {
        "id": "DXAMdaWhPDK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to load a trained model\n",
        "def load_model(model_path):\n",
        "  \"\"\"\n",
        "  Loads a saved model from a specified path.\n",
        "  \"\"\"\n",
        "\n",
        "  print(f\"Loading saved model from: {model_path}\")\n",
        "  model = tf.keras.models.load_model(model_path,\n",
        "                                     custom_objects={\"KerasLayer\":hub.KerasLayer})\n",
        "  return model"
      ],
      "metadata": {
        "id": "vFtUOtRCTXDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save our model trained on 1000 images\n",
        "save_model(model,suffix=\"1000-images-mobilenetv2-Adam\")"
      ],
      "metadata": {
        "id": "d0DlQxmqUk-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a trained model\n",
        "loaded_1000_image_model = load_model('drive/MyDrive/Dog Vision/models/20220210-11101644491415-1000-images-mobilenetv2-Adam.h5')"
      ],
      "metadata": {
        "id": "PDAiD9nHU5ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the pre-saved model\n",
        "model.evaluate(val_data)"
      ],
      "metadata": {
        "id": "qKYBTqMkVLgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the loaded model\n",
        "loaded_1000_image_model.evaluate(val_data)"
      ],
      "metadata": {
        "id": "BJI-fwEnVWMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a model on the full data"
      ],
      "metadata": {
        "id": "kf-GJvGwVgnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(X),len(y)"
      ],
      "metadata": {
        "id": "fL_ddviQWW-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a data batch with the full data set\n",
        "full_data =  create_data_batches(X,y)"
      ],
      "metadata": {
        "id": "97NL3OM7WZsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data"
      ],
      "metadata": {
        "id": "A-1S7rmuW-4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model for full data\n",
        "full_model=create_model()"
      ],
      "metadata": {
        "id": "__mqQD_xXBZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create full model callbacks\n",
        "full_model_tensorboard = create_tensorboard_callback()\n",
        "#No validation set when training on all thed data, so we can't monitor validation accuracy\n",
        "full_model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",\n",
        "                                                             patience=3)"
      ],
      "metadata": {
        "id": "yRx2tfP6XdSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Running the cell below will take a while because the GPU we're using in the runtime has to load all of the images into memory."
      ],
      "metadata": {
        "id": "_-DM1zKqYPFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the full model to the full data\n",
        "full_model.fit(x=full_data,\n",
        "               epochs=NUM_EPOCHS,\n",
        "               callbacks=[full_model_tensorboard,full_model_early_stopping])"
      ],
      "metadata": {
        "id": "Q5AmLB-tX9MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(full_model,suffix=\"full-image-set-mobilenetv2-Adam\")"
      ],
      "metadata": {
        "id": "FNsamvqhYzUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changed the step here. Didn't use Load Model"
      ],
      "metadata": {
        "id": "vLVyfvFxZn-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the full model\n",
        "#I did this\n",
        "loaded_full_model=full_model\n",
        "# Instead it should be\n",
        "#Loaded_full_model = load_model(\"modelpath\")"
      ],
      "metadata": {
        "id": "6_i0Ev3RZPUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making predictions on the test dataset\n",
        "\n",
        "Since our model has been trained on images in the form of Tensor batches, to make predictiomns on the test data we'll\n",
        "have to get it into the same format.\n",
        "\n",
        "Luckily we created `create_data_batches()` earlier which can take a list of filenames as inout and conver them into Tensor batches.\n",
        "\n",
        "To make predictions on the test data, we'll:\n",
        "* Get the test image filenames\n",
        "* Convert the filenames into test data batches using `create_data_batches()` and setting the `test_data` parameter to `True` (since the test data doesn't have labels).\n",
        "* Make a predictions array by passing the test batches to the predict() method called on our model"
      ],
      "metadata": {
        "id": "HVYkBF2y2WmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test image filenames\n",
        "test_path =\"drive/MyDrive/Dog Vision/test/\"\n",
        "test_filenames =[test_path + fname for fname in os.listdir(test_path)]\n",
        "test_filenames[:10]"
      ],
      "metadata": {
        "id": "XYmSEgnW2AVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_filenames)"
      ],
      "metadata": {
        "id": "kh6w8ZG459jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create test data batch\n",
        "test_data = create_data_batches(test_filenames,test_data=True)"
      ],
      "metadata": {
        "id": "4Kyxs7QO6J9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "id": "k0dIWhmo6V4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Calling `predict()` on our full model and passing it the test data batch will take a long time to run."
      ],
      "metadata": {
        "id": "D1ZLkyeh7aEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on test data batch using the loaded full model\n",
        "test_predictions = loaded_full_model.predict(test_data,\n",
        "                                             verbose=1)"
      ],
      "metadata": {
        "id": "6qjO_GGQ6wLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save predictions (NumPy array) to csv file (for access later)\n",
        "np.savetxt(\"drive/MyDrive/Dog Vision/preds_array.csv\",test_predictions,delimiter=\",\")"
      ],
      "metadata": {
        "id": "X5IwJYMR7uOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load predictions (Numpy array) from csv file\n",
        "test_predictions = np.loadtxt(\"drive/MyDrive/Dog Vision/preds_array.csv\",delimiter=\",\")"
      ],
      "metadata": {
        "id": "ty1TvkHq8iD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions[:10]"
      ],
      "metadata": {
        "id": "mFhTkbC689gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions.shape"
      ],
      "metadata": {
        "id": "VrhK8yE99cRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing test dataset predictions for Kaggle\n",
        "\n",
        "Looking at the Kaggle sample submission, we find that it wants our models prediction probability outputs in a DataFrame with an ID and a column for each dog breed.https://www.kaggle.com/c/dog-breed-identification/overview/evaluation\n",
        "\n",
        "To get the data in this format, we'll:\n",
        "* Create a pandas DataFrame with an ID column as well as a column for each dog breed\n",
        "* Add data to the ID column by extracting the test image ID's form their filepaths\n",
        "* Add data (the prediction probabilities to each of the dog breed columns\n",
        "* Export the DataFrame as a CSV to submit it to Kaggle"
      ],
      "metadata": {
        "id": "CpDVGRY79xVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pandas DataFrame with empty columns\n",
        "preds_df = pd.DataFrame(column=[\"id\"]+list(unique_breeds))\n",
        "preds_df.head()"
      ],
      "metadata": {
        "id": "4HG3BajC9fOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Append test image ID's to predictions DataFrame\n",
        "test_ids=[os.path.splitext(path)[0] for path in os.listdir(test_path)]\n",
        "preds_df[\"id\"]=test_ids"
      ],
      "metadata": {
        "id": "pGxNw1oS_rEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_df.head()"
      ],
      "metadata": {
        "id": "5ydpjv43Ann2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the prediction probabilities to each dog breed column\n",
        "preds_df[list(unique_breeds)] = test_predictions\n",
        "preds_df.head()"
      ],
      "metadata": {
        "id": "urG3m-YUAvMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save our predictions dataframe to CSV for submission to Kaggle\n",
        "preds_df.to_csv(\"drive/My Drive/Dog Vision/full_model_predictions_submisiion_1_mobilenetV2.csv\",\n",
        "                index=False)"
      ],
      "metadata": {
        "id": "5zxquyR5BXcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making predictions on custom images\n",
        "\n",
        "To make predictions on custom images, we'll:\n",
        "* Get the filepaths of our own images.\n",
        "* Turn the filepaths into data batches using `create_data_batches()`. And since our custom images won't have labels, we set the `test_data` parameter to `True`.\n",
        "* Pass the custom image data batch to our model's `predict()` method\n",
        "* Convert the prediction output probabilities to predictions labels\n",
        "* Compare the predicted labels to custom images.\n",
        "\n"
      ],
      "metadata": {
        "id": "sgCx_23-B5H0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get custom image filepaths\n",
        "custom_path = \"drive/My Drive/Dog Vision/my-dog-photos\"\n",
        "custom_image_paths = [custom_path+fname for fname in os.listdir(custom_path)]"
      ],
      "metadata": {
        "id": "dme7hqZtCwFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_images_paths"
      ],
      "metadata": {
        "id": "zwLXswvNDMNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn custom images into batch datasets\n",
        "custom_data = create_data_batches(custom_image_paths,test_data=True)\n",
        "custom_data\n"
      ],
      "metadata": {
        "id": "hS7FeoQ8DQXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the custom data\n",
        "custom_preds = loaded_full_model.predict(custom_data)"
      ],
      "metadata": {
        "id": "9MmlEGdKESHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_preds.shape"
      ],
      "metadata": {
        "id": "yQ1S2waLEawt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get custom image prediction labels\n",
        "custom_pred_labels = [get_pred_label(custom_preds[i]) for i in range(len(custom_preds))]\n",
        "custom_pred_labels"
      ],
      "metadata": {
        "id": "Yo89BKLiEcYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get custom images (our unbatchify() won't work since there aren't labels... maybe we could fix this later)\n",
        "custom_images = []\n",
        "# Loop through unbatched data\n",
        "for image in custom_data.unbatch().as_numpy_iterator():\n",
        "  custom_images.append(image)"
      ],
      "metadata": {
        "id": "VePFS58zE0TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check custom image predictions\n",
        "plt.figure(figsize=(10,10))\n",
        "for i,image in enumerate(custom_images):\n",
        "  plt.subplot(1,3,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.title(custom_pred_labels[i])\n",
        "  plt.imshow(image)\n",
        "  "
      ],
      "metadata": {
        "id": "00OghLaJFWrw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
